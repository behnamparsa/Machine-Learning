{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a20cbd5",
   "metadata": {},
   "source": [
    "# Assignment 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c34819",
   "metadata": {},
   "source": [
    "### GOAL\n",
    "After Assignment 4, you should understand and be able to apply the following functions (in addition to the ones from previous assignments):\n",
    "- https://pandas.pydata.org/docs/reference/api/pandas.Series.prod.html\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.BernoulliNB.html\n",
    "- https://pandas.pydata.org/docs/reference/api/pandas.Series.unique.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6a496a",
   "metadata": {},
   "source": [
    "## Exercises "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98abae23",
   "metadata": {},
   "source": [
    "***Ex1.*** Load a dataframe named 'info' from the following dictionary. The target variable is the column 'age', i.e., we try to predict the age based on some personal information.\n",
    "\n",
    "```python\n",
    "info = [\n",
    "    {'has_children':False, 'has_car':False,  'has_pet':True, 'age':'0-25yo'},\n",
    "    {'has_children':False, 'has_car':False,  'has_pet':False,  'age':'0-25yo'},\n",
    "    {'has_children':False, 'has_car':False,  'has_pet':True,   'age':'0-25yo'},\n",
    "    {'has_children':False, 'has_car':True,   'has_pet':False,  'age':'0-25yo'},\n",
    "    {'has_children':False, 'has_car':False,  'has_pet':True,   'age':'0-25yo'},\n",
    "    {'has_children':False, 'has_car':False,  'has_pet':False,   'age':'0-25yo'},\n",
    "    {'has_children':False, 'has_car':False,  'has_pet':True,  'age':'0-25yo'},\n",
    "    {'has_children':True,  'has_car':False,  'has_pet':False,   'age':'0-25yo'},\n",
    "\n",
    "    {'has_children':True,  'has_car':True,  'has_pet':True,  'age':'25-50yo'},\n",
    "    {'has_children':False, 'has_car':True,  'has_pet':False,   'age':'25-50yo'},\n",
    "    {'has_children':True,  'has_car':True,  'has_pet':True,  'age':'25-50yo'},\n",
    "    {'has_children':False, 'has_car':False, 'has_pet':False,   'age':'25-50yo'},\n",
    "    {'has_children':True,  'has_car':True,  'has_pet':True, 'age':'25-50yo'},\n",
    "    {'has_children':False, 'has_car':True, 'has_pet':False,   'age':'25-50yo'},\n",
    "    {'has_children':True,  'has_car':True,  'has_pet':True, 'age':'25-50yo'},\n",
    "    {'has_children':False, 'has_car':True, 'has_pet':False,  'age':'25-50yo'},\n",
    "    \n",
    "    {'has_children':True,  'has_car':False, 'has_pet':True, 'age':'50+'},\n",
    "    {'has_children':True,  'has_car':False,  'has_pet':False, 'age':'50+'},\n",
    "    {'has_children':True,  'has_car':True,  'has_pet':True, 'age':'50+'},\n",
    "    {'has_children':False, 'has_car':False, 'has_pet':False,  'age':'50+'},\n",
    "]\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30af9c3a",
   "metadata": {},
   "source": [
    "***Ex2.*** Create a function 'prior_target' (use structure below). The function should return the prior (=probability) of the value. For instance, prior_target(info, 'age','25-50yo') returns the probability of the age being 25-50yo.\n",
    "\n",
    "```python\n",
    "def prior(df, col, value):\n",
    "    return ...\n",
    "\n",
    "prior(info, 'age','25-50yo')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3513e703",
   "metadata": {},
   "source": [
    "***Ex3.*** Create a function 'cond_probability' (use structure below). The function should return the value's prior (=probability) when the filter_col is equal to filter_val. For instance, cond_probability(info, 'age', '25-50yo', 'has_car',True) returns the probability of having a car for people that are between 25 and 50 yo. \n",
    "```python\n",
    "def cond_probability(df, filter_col, filter_val, col, value):\n",
    "    return ...\n",
    "\n",
    "cond_probability(info, 'age', '25-50yo', 'has_car',True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923d5e33",
   "metadata": {},
   "source": [
    "***Ex4.*** Given \"obs\" (see below), calculate the probability of the target variable 'age' to be '50+'. Hint: loop and store two lists: (1) the conditional probabilities and (2) the prior for each feature. Then, calculate the product of these two lists and apply the formula: $p(c_i|w) = \\frac{p(w|c_i)p(c_i)}{p(w)}$\n",
    "\n",
    "```python\n",
    "obs = {'has_children':False, 'has_car':True, 'has_pet':True}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e028e630",
   "metadata": {},
   "source": [
    "***Ex5.*** Do the same as above but now loop through each class and return the one with the highest probability. That's it; you implemented Naive Bayes üèÜ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597125a6",
   "metadata": {},
   "source": [
    "***Ex6.*** Use BernoulliNB from scikit to predict the class of obs (see: https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.BernoulliNB.html). Note1: there are several implementations of NaiveBayes in scikit. Because our features are binary, BernoulliNB is the best approach. Note2: make sure to present the features correctly, i.e., in the order used to train the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
