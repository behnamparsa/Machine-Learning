{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8a20cbd5",
   "metadata": {},
   "source": [
    "# Assignment Week 08"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "34c34819",
   "metadata": {},
   "source": [
    "### GOAL\n",
    "After Assignment 8, you should understand and be able to apply the following functions (in addition to the ones from the previous assignments):\n",
    "- https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_pickle.html\n",
    "- https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.entropy.html\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.tree.plot_tree.html\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html (new: stratify parameter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6a496a",
   "metadata": {},
   "source": [
    "## Exercises "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98abae23",
   "metadata": {},
   "source": [
    "***Ex1.*** Load the **pickle** file \"titanic.pickle\" and store it in a dataframe named titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5138416e",
   "metadata": {},
   "source": [
    "***Ex2.*** Use scipy to measure the entropy given that the target variable is 'alive' (https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.entropy.html). Don't forget to use a base 2. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c0ab1e",
   "metadata": {},
   "source": [
    "***Ex3.*** Measure the entropy from ex2 \"by hand\"; i.e., using math.log(). Again, don't forget to use a base 2. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00f100c",
   "metadata": {},
   "source": [
    "***Ex4.*** Let's split the dataset into 2 using the feature 'alone'. What are the resulting two entropies? Then, calculate the weighted average of these two entropies. The target variable is still 'alive'. Feel free to use scipy or to calculate the entropy by hand. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e15bc22",
   "metadata": {},
   "source": [
    "***Ex5.*** Use the entropy from Ex3 and Ex4 to measure the resulting information gain"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "837e6712",
   "metadata": {},
   "source": [
    "***Ex6.*** Looking at the decision tree introduced in the Tutorial-Week-08,  can you spot and explain the 4 ways that exist to end the recursion? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb1c640",
   "metadata": {},
   "source": [
    "***Ex7.*** Load the data from 'cancer.csv' in a variable called cancer. Set the index to be the column 'id' (never use an index as a feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6b55fd",
   "metadata": {},
   "source": [
    "***Ex8.*** Split the dataset into two parts using a random stratified sampling: (1) training 80%, (2) testing 20%. (see: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html). How can you 'spot' that it was indeed a stratified sampling?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605c1679",
   "metadata": {},
   "source": [
    "***Ex9.*** Implement decision trees using scikit-learn (with the criterion set to 'entropy' and a max depth of 6). Use the training dataset for building the tree and the validation set to evaluate the results (using f1 score). Notice that if you re-split (Ex8), you get a new performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ee7ad4",
   "metadata": {},
   "source": [
    "***Ex10.*** Let's use a stratified Kfold splitting (with k=10) to get the average f1_score "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120e079a",
   "metadata": {},
   "source": [
    "***Ex11.*** Build a decision tree using the whole dataset (with k=3). Visualize the decision tree using https://scikit-learn.org/stable/modules/generated/sklearn.tree.plot_tree.html and play with the parameters to make it interpretable (e.g., add names of features)\n",
    "```python\n",
    "# Add the following two lines just before plot_tree() to make your tree more readable\n",
    "from matplotlib import pyplot as plt\n",
    "fig, axes = plt.subplots(nrows = 1,ncols = 1,figsize = (8,4), dpi=300)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f75b584",
   "metadata": {},
   "source": [
    "***Ex12.*** Using a stratified ksplitting with k=10, choose the best maximum depth (from 1 to 20). Plot a graph of the f1 score."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
